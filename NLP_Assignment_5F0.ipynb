{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_5F0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajurgd/NLP/blob/main/NLP_Assignment_5F0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARAGRAPH :- \n",
        "Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.\n",
        "Solving an NLP problem is a multi-stage process. We need to clean the unstructured text data first before we can even think about getting to the modelling stage. Cleaning the data consists of a few key steps."
      ],
      "metadata": {
        "id": "N-pI966SMxGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IegfjWoPM4cD",
        "outputId": "41e49e83-9a68-4125-e6c8-662711b00c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : Split the above paragraph into sentences"
      ],
      "metadata": {
        "id": "ra--Gj33M-PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.Solving an NLP problem is a multi-stage process. We need to clean the unstructured text data first before we can even think about getting to the modelling stage. Cleaning the data consists of a few key steps.\"\n",
        "sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uut9T9DM4Zg",
        "outputId": "9ae87e78-41d6-4d07-9eb6-84a2c48f49af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Are you fascinated by the amount of text data available on the internet?',\n",
              " 'Are you looking for ways to work with this text data but aren’t sure where to begin?',\n",
              " 'Machines, after all, recognize numbers, not the letters of our language.',\n",
              " 'And that can be a tricky landscape to navigate in machine learning.Solving an NLP problem is a multi-stage process.',\n",
              " 'We need to clean the unstructured text data first before we can even think about getting to the modelling stage.',\n",
              " 'Cleaning the data consists of a few key steps.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 : Split the above paragraph into words"
      ],
      "metadata": {
        "id": "E7h5aDA6MUYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwR13EjwNQ6i",
        "outputId": "1216d1c7-0e96-48be-d67f-c9cb47dce699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Are',\n",
              " 'you',\n",
              " 'fascinated',\n",
              " 'by',\n",
              " 'the',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'text',\n",
              " 'data',\n",
              " 'available',\n",
              " 'on',\n",
              " 'the',\n",
              " 'internet',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'looking',\n",
              " 'for',\n",
              " 'ways',\n",
              " 'to',\n",
              " 'work',\n",
              " 'with',\n",
              " 'this',\n",
              " 'text',\n",
              " 'data',\n",
              " 'but',\n",
              " 'aren',\n",
              " '’',\n",
              " 't',\n",
              " 'sure',\n",
              " 'where',\n",
              " 'to',\n",
              " 'begin',\n",
              " '?',\n",
              " 'Machines',\n",
              " ',',\n",
              " 'after',\n",
              " 'all',\n",
              " ',',\n",
              " 'recognize',\n",
              " 'numbers',\n",
              " ',',\n",
              " 'not',\n",
              " 'the',\n",
              " 'letters',\n",
              " 'of',\n",
              " 'our',\n",
              " 'language',\n",
              " '.',\n",
              " 'And',\n",
              " 'that',\n",
              " 'can',\n",
              " 'be',\n",
              " 'a',\n",
              " 'tricky',\n",
              " 'landscape',\n",
              " 'to',\n",
              " 'navigate',\n",
              " 'in',\n",
              " 'machine',\n",
              " 'learning.Solving',\n",
              " 'an',\n",
              " 'NLP',\n",
              " 'problem',\n",
              " 'is',\n",
              " 'a',\n",
              " 'multi-stage',\n",
              " 'process',\n",
              " '.',\n",
              " 'We',\n",
              " 'need',\n",
              " 'to',\n",
              " 'clean',\n",
              " 'the',\n",
              " 'unstructured',\n",
              " 'text',\n",
              " 'data',\n",
              " 'first',\n",
              " 'before',\n",
              " 'we',\n",
              " 'can',\n",
              " 'even',\n",
              " 'think',\n",
              " 'about',\n",
              " 'getting',\n",
              " 'to',\n",
              " 'the',\n",
              " 'modelling',\n",
              " 'stage',\n",
              " '.',\n",
              " 'Cleaning',\n",
              " 'the',\n",
              " 'data',\n",
              " 'consists',\n",
              " 'of',\n",
              " 'a',\n",
              " 'few',\n",
              " 'key',\n",
              " 'steps',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3 : Find stem and lemma words for the given words?\n",
        "\n",
        "“cats\"\n",
        "\"trouble\"\n",
        "\"troubling\"\n",
        "\"troubled\"\n",
        "“having”\n",
        "“Corriendo”\n",
        "“at”\n",
        "“was”"
      ],
      "metadata": {
        "id": "uga3zBDaNEQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEMMING\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemming=SnowballStemmer('english')\n",
        "names=[\"cats\",\"trouble\",\"troubling\",\"having\",\"Corriendo\",\"at\",\"was\"]\n",
        "for words in names:\n",
        "  root = stemming.stem(words)\n",
        "  print(root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00-DwBgQN50f",
        "outputId": "ff8f7723-eb38-4cb2-aff2-75316776d22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "troubl\n",
            "troubl\n",
            "have\n",
            "corriendo\n",
            "at\n",
            "was\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMATIZATION\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatization = WordNetLemmatizer()\n",
        "for words in names:\n",
        "  root = lemmatization.lemmatize(words)\n",
        "  print(root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQcEzY4xNrbU",
        "outputId": "94c4d579-c667-49de-9d14-52ffc3905f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "trouble\n",
            "troubling\n",
            "troubled\n",
            "having\n",
            "Corriendo\n",
            "at\n",
            "wa\n"
          ]
        }
      ]
    }
  ]
}